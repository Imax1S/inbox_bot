# ðŸ§  AI Knowledge Inbox Filter Agent (Inbox Agent Bot)

## ðŸŽ¯ Project Goal
Create an **intelligent knowledge curator agent** that:
- Accepts unstructured data via Telegram
- Accumulates it throughout the week
- Once a week (on trigger) processes all messages using LLM
- Creates structured Markdown notes in Obsidian Vault

**Core principle:**
> â— Better to save something doubtful than delete something useful.

**Personal project goals:**
- Avoid procrastination (don't dive into studying every idea immediately)
- Accumulate ideas/questions/links and process them in batches
- Learn new technologies: LangChain, Anthropic API, Docker, agent systems

---

## ðŸ—ï¸ Technical Architecture

### Tech Stack
- **Python 3.11+**
- **python-telegram-bot** â€” receiving messages from Telegram
- **Anthropic API (Claude Sonnet 4)** â€” processing and structuring knowledge
- **LangChain** â€” framework for working with LLMs (chains, prompts, parsing)
- **Jina Reader API** â€” parsing web pages to markdown
- **youtube-transcript-api** â€” fetching YouTube video transcripts (automatic and manual)
- **Docker** â€” containerization and environment isolation
- **SQLite** â€” local DB for processing history
- **JSON** â€” storing user_profile (interests and priorities)

### Operating Mode
**Trigger-based run (once a week):**
1. Start Docker container: `docker run inbox-agent-bot`
2. Bot connects to Telegram and retrieves all accumulated messages
3. Processes them through Claude Sonnet 4
4. Creates structured notes in Obsidian
5. Completes work and shuts down

**Queue storage:** while bot is offline, messages are stored on Telegram servers

### Paths and Configuration
- **Obsidian Vault:** `/Users/ionko/Documents/my_vault/life/weekly/`
- **Weekly digest:** `YYYY-Www_digest.md` (e.g., `2025-W03_digest.md`)
- **Themed notes:** separate `.md` files in the same folder

---

## ðŸ“¥ Input Data Format

### Message Types
1. **Simple text notes** â€” thoughts, ideas, observations
2. **Research queries** â€” "Porcelain in China", "How does RAG work"
   - Agent should do a small search and create a paragraph of basic knowledge
3. **Article links** â€” parsed via Jina Reader
4. **YouTube links** â€” transcripts extracted via youtube-transcript-api (if transcripts exist â€” analyzed, if not â€” only link saved with note)
5. **Quotes and thought fragments** â€” any unstructured text

### Examples
- "Porcelain in China" â†’ agent creates a note with brief topic overview
- https://example.com/article â†’ agent reads article and creates summary
- https://youtube.com/watch?v=xxx â†’ agent extracts transcript or title
- "Idea: make a bot for knowledge filtering" â†’ saved as raw idea

---

## ðŸ“¤ Output Format (Obsidian)

### Weekly Digest Structure
**File:** `2025-W03_digest.md`

```markdown
# Weekly Digest â€” 2025 Week 03

## ðŸ“Š Statistics
- Total messages: 42
- Notes created: 8
- Research queries: 3
- Links processed: 12

## ðŸ—‚ï¸ Topics of the Week

### AI/ML
- [[mcp_protocol_deep_dive]] â€” Model Context Protocol breakdown
- [[rag_architectures_comparison]] â€” comparison of RAG approaches

### Mathematics
- [[probability_puzzle_monty_hall]] â€” Monty Hall paradox
- [[linear_algebra_practical_uses]] â€” practical applications of linear algebra

### Politics
- [[geopolitics_2025_trends]] â€” trends in international relations

### Finance
- [[investment_basics_summary]] â€” basic investment principles

### IT/Architecture
- [[aws_ci_cd_best_practices]] â€” CI/CD best practices in AWS

### Product/Leadership
- [[startup_team_building_notes]] â€” notes on team building

## âš ï¸ Needs Attention
- [[uncertain_topic_xyz]] #needs_review â€” not sure about relevance
```

### Themed Note Structure
**File:** `mcp_protocol_deep_dive.md`

```markdown
# MCP Protocol Deep Dive

## ðŸŽ¯ Quick Summary
Model Context Protocol (MCP) â€” open protocol for connecting AI assistants to external data sources. Developed by Anthropic.

## ðŸ’¡ Key Ideas
- Allows Claude to work with files, DBs, APIs without hacks
- Architecture: client-server, JSON-RPC
- Can create custom MCP servers for custom sources

## ðŸ”— Links and Sources
- [Official MCP Documentation](https://modelcontextprotocol.io)
- [Video: MCP Tutorial](https://youtube.com/watch?v=xxx)
  - Transcript: "MCP simplifies context integration..."

## ðŸ¤” Thoughts and Interpretations
- This solves the "AI can't see my files" problem
- Could potentially connect to Obsidian via MCP
- Worth trying to write a custom MCP server

## â“ Questions and Doubts
- How safe is it to give AI access to files?
- Are there limits on context size transmitted?

## ðŸ·ï¸ Tags
#ai #mcp #anthropic #tools #learn #actionable
```

---

## ðŸ§  Filter System (Agent Logic)

### 1ï¸âƒ£ Usefulness Filter
**Question:** Does this carry knowledge or knowledge potential?

**Criteria:**
- Is there an idea, insight, fact, hypothesis?
- Related to my interests? (see user_profile.json)
- Could it be useful in the future?

**Decisions:**
- âœ… Keep
- âš ï¸ Keep with `#needs_review` marker
- âŒ Delete (only if 100% garbage)

### 2ï¸âƒ£ Novelty Filter
**Question:** Is this a duplicate or new information?

**Logic:**
- Compare only with current week's data (not with Obsidian history)
- If topic repeats â†’ merge into one note
- If duplicate â†’ mark as `#duplicate`

### 3ï¸âƒ£ Thought Maturity Filter
**Classification:**
- ðŸŒ± `#raw` â€” raw idea, thought fragment
- ðŸŒ¿ `#developing` â€” developing concept
- ðŸŒ³ `#mature` â€” formed thought

### 4ï¸âƒ£ Actionability Filter
**Question:** Can this be turned into action?

**Tags:**
- `#actionable` â€” can do/try
- `#theory` â€” abstract knowledge
- `#idea` â€” project/experiment idea
- `#reference` â€” reference information

### 5ï¸âƒ£ Confidence Filter (anti-deletion)
**Rule:** If agent is uncertain â†’ DON'T delete, mark it!

**Doubt markers:**
- `âš ï¸ #needs_review` â€” requires manual review
- `â“ #uncertain` â€” unsure about relevance
- `ðŸŸ¡ #low_confidence` â€” low confidence in categorization

---

## ðŸ·ï¸ Tagging System

### Content Type
- `#thought` â€” thought, observation
- `#link` â€” processed link
- `#quote` â€” quote
- `#research` â€” research query
- `#video` â€” video (YouTube etc.)

### Topics (from user_profile.json)
- `#math` â€” mathematics
- `#ai` â€” AI/ML
- `#politics` â€” politics
- `#finance` â€” finance
- `#it` â€” IT, architecture, DevOps
- `#product` â€” product, startups
- `#leadership` â€” management, team lead
- `#systems` â€” systems thinking

### State
- `#raw` / `#developing` / `#mature`
- `#actionable` / `#theory` / `#idea` / `#reference`
- `#needs_review` / `#uncertain` / `#low_confidence`
- `#weekly_digest`

---

## ðŸŽ›ï¸ User Profile (user_profile.json)

Interest and priority profile is created separately (not in this bot).

**File structure:**
```json
{
  "interests": {
    "math": {
      "weight": 0.9,
      "keywords": ["mathematics", "problems", "proofs", "algorithms"],
      "priority": "high"
    },
    "ai": {
      "weight": 1.0,
      "keywords": ["AI", "ML", "LLM", "RAG", "MCP", "agents", "Claude", "GPT"],
      "priority": "critical"
    },
    "politics": {
      "weight": 0.85,
      "keywords": ["politics", "geopolitics", "elections", "diplomacy"],
      "priority": "high"
    },
    "finance": {
      "weight": 0.7,
      "keywords": ["finance", "investments", "stocks", "budget"],
      "priority": "medium"
    },
    "it": {
      "weight": 0.95,
      "keywords": ["architecture", "AWS", "CI/CD", "Docker", "Kubernetes"],
      "priority": "high"
    },
    "product": {
      "weight": 0.9,
      "keywords": ["startup", "product", "team", "team lead", "management"],
      "priority": "high"
    }
  },
  "filters": {
    "min_relevance_score": 0.3,
    "auto_reject_below": 0.1,
    "prefer_practical": true,
    "prefer_depth": true
  },
  "blacklist": {
    "topics": ["celebrity gossip", "sports scores", "fashion trends"],
    "keywords": ["clickbait", "top-10", "shock"]
  }
}
```

**Profile creation:** use prompt (see above) in a separate AI chat.

---

## ðŸ”„ Processing Workflow

### Step 1: Message Retrieval
- Connect to Telegram Bot API
- Retrieve all unread messages
- Save to local DB (SQLite)

### Step 2: Preprocessing
- Recognize message type (text, link, YouTube, research query)
- Parse web links via Jina Reader API
- Extract YouTube transcripts via youtube-transcript-api:
  - Attempt to get transcripts (Russian or English)
  - If no transcripts â†’ save URL with `#needs_manual_review` marker
- For research queries: web search or generate basic knowledge via Claude

### Step 3: Processing through Claude
- Form prompt considering user_profile.json
- Send all messages in one batch (30-50 messages per 200k context)
- Apply filters (usefulness, novelty, maturity, actionability, confidence)
- Group by topics
- Create structured notes

### Step 4: Output Generation
- Create Weekly Digest file
- Create separate themed notes
- Save to `/Users/ionko/Documents/my_vault/life/weekly/`

### Step 5: Logging and Completion
- Save processing metrics to DB
- Optionally update user_profile.json (topic usage statistics)
- Complete container work

---

## ðŸ§  Agent Operating Principles

> **If uncertain â€” DON'T delete.**

> **If in doubt â€” mark with a marker.**

> **If you see potential â€” save and structure.**

Agent is an **editor and curator**, not an archiver:
- Removes noise
- Highlights meaning
- Connects ideas
- Makes cautious decisions
- Marks doubts instead of deleting

---

## ðŸ”® Future Improvements (v2.0+)

### Automatic Profile Learning
- Track which notes you read/edit
- Automatic adjustment of interest weights
- Hints: "You've been studying this topic for 3 weeks straight"

### Note Linking
- Automatic creation of [[wikilinks]] between related topics
- Maintain knowledge graph
- Detect recurring thought patterns

### Advanced Search
- Vector search across all Obsidian notes (embeddings)
- Novelty filter at knowledge base level, not just weekly

### External Source Integration
- Automatic import from Pocket, Instapaper, Readwise
- RSS feeds for automatic topic tracking
- Integration with research papers (arXiv, Google Scholar)

---

## ðŸ“¦ Project Structure (Expected)

```
inbox_agent_bot/
â”œâ”€â”€ docker/
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ docker-compose.yml
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ main.py                 # Entry point
â”‚   â”œâ”€â”€ telegram_client.py      # Telegram message retrieval
â”‚   â”œâ”€â”€ preprocessor.py         # Link, YouTube, message type parsing
â”‚   â”œâ”€â”€ llm_agent.py            # Claude work via LangChain
â”‚   â”œâ”€â”€ obsidian_writer.py      # Markdown file creation
â”‚   â”œâ”€â”€ database.py             # SQLite for history
â”‚   â””â”€â”€ config.py               # Load user_profile.json and env vars
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ user_profile.json       # Interest profile
â”‚   â””â”€â”€ .env                    # API keys (Telegram, Anthropic, Jina)
â”œâ”€â”€ data/
â”‚   â””â”€â”€ history.db              # SQLite DB
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ system_prompt.txt       # System prompt for Claude
â”‚   â””â”€â”€ filters.txt             # Filter descriptions for agent
â”œâ”€â”€ tests/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

---

## ðŸš€ Development Roadmap

### Phase 1: MVP (Minimum Viable Product)
- [ ] Telegram bot receives messages
- [ ] Basic Claude Sonnet 4 integration
- [ ] Simple text processing (without links)
- [ ] Create Weekly Digest + one themed note
- [ ] Docker container for running

### Phase 2: Full Features
- [ ] Web link parsing (Jina Reader)
- [ ] YouTube support (transcripts)
- [ ] Research queries (web search or knowledge generation)
- [ ] Apply all 5 filters
- [ ] Load user_profile.json

### Phase 3: Polish
- [ ] Logging and statistics
- [ ] Error handling and fallback scenarios
- [ ] Tests (unit + integration)
- [ ] User documentation

### Phase 4: Future
- [ ] Automatic profile learning
- [ ] Vector search across Obsidian
- [ ] Web interface for configuration
- [ ] Voice message support

---

## ðŸ“š Useful Resources

- [Anthropic API Docs](https://docs.anthropic.com/)
- [LangChain Documentation](https://python.langchain.com/)
- [python-telegram-bot](https://docs.python-telegram-bot.org/)
- [Jina Reader API](https://jina.ai/reader/)
- [youtube-transcript-api (GitHub)](https://github.com/jdepoix/youtube-transcript-api)
- [Obsidian Markdown Spec](https://help.obsidian.md/Editing+and+formatting/Basic+formatting+syntax)

---

## ðŸŽ¯ Project Success = Learn New Technologies + Get Working Tool

This project is not just a filter, but a **second brain-editor** that:
- Reduces cognitive load
- Respects uncertainty
- Helps turn chaos into an internal knowledge system
- Allows me to learn LangChain, Claude API, agent systems in practice
